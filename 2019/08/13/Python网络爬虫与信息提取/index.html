


<!DOCTYPE html>
<html lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<title>Python网络爬虫与信息提取 [ 市井烟火气 ]</title>
	
	
	<!-- stylesheets list from _config.yml -->
	
	<link rel="stylesheet" href="/css/PreciousJoy.css">
	
	<link rel="stylesheet" href="/css/top-bar.css">
	
	<link rel="stylesheet" href="/css/menu-outer.css">
	
	<link rel="stylesheet" href="/css/content-outer.css">
	
	<link rel="stylesheet" href="/css/bottom-outer.css">
	
	<link rel="stylesheet" href="/css/atom-one-dark.css">
	
	<link rel="stylesheet" href="/css/recent-posts-item.css">
	
	<link rel="stylesheet" href="/css/article-sidebar-toc.css">
	
	<link rel="stylesheet" href="/css/jquery.fancybox.min.css">
	
	<link rel="stylesheet" href="/css/search.css">
	
	<link rel="stylesheet" href="/css/toc.css">
	
	<link rel="stylesheet" href="/css/sidebar.css">
	
	<link rel="stylesheet" href="/css/archive.css">
	
	<link rel="stylesheet" href="/css/jquery.mCustomScrollbar.min.css">
	
	<link rel="stylesheet" href="/css/Z-last-cover-others.css">
	
	
	
</head>




<body id="wrapper">

	<div id="">
		
		<div id="top-bar">
			
			<div id="avatar-box">
				<img class="avatar" src="/images/avatar.png" alt="avatar">
			</div>

			<div id="top-bar-text">
				<div id="top-bar-title">
					fireworks99
				</div>
				<div id="top-bar-slogan">
					keep hungry keep foolish
				</div>
			</div>

		</div>

		<div id="menu-outer">
			<div id="menu-inner">
				
				
				<div class="menu-item">
					<a href="/">Home</a>
				</div>
				
				<div class="menu-item">
					<a href="/about">About</a>
				</div>
				
				<div class="menu-item">
					<a href="/archives">Archives</a>
				</div>
				

				<div class="menu-item menu-item-search">
					
  <span class="local-search local-search-google local-search-plugin">
      <input type="search" placeholder="站内搜索" id="local-search-input" class="local-search-input-cls" style="">
      <div id="local-search-result" class="local-search-result-cls"></div>
  </span>
	
				</div>

			</div>
		</div>

		<div id="content-outer">
			<div id="content-inner">

				
<div id="details">
	
	<article id="details-post">
		<div id="details-post-item">
			<h1>Python网络爬虫与信息提取</h1>
			<h2 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h2><blockquote>
<ol>
<li>request.get()</li>
<li>处理异常</li>
<li>通用框架</li>
<li>模拟浏览器访问</li>
<li>向搜索引擎提交关键词获取搜索结果</li>
<li>网络图片(视频、动画等二进制资源)的爬取与存储</li>
<li>大量图片的爬取与存储</li>
<li>IP地址归属地的自动查询</li>
</ol>
</blockquote>
<a id="more"></a>
<h2 id="一-request-get"><a href="#一-request-get" class="headerlink" title="一.request.get()"></a>一.request.get()</h2><pre><code class="lang-python">import requests

# 构造一个向服务器请求资源的Request对象，返回一个包含服务器资源的Response对象(即r)
r = requests.get(&quot;http://www.baidu.com&quot;)

# Response对象的五种属性
print(r.status_code )
print(r.encoding) # 猜测编码方式
print(r.apparent_encoding) # 分析编码方式
r.encoding = r.apparent_encoding
print(r.text)
print(r.content) # HTTP响应内容的二进制形式(还原图片等)
</code></pre>
<h2 id="二-处理异常"><a href="#二-处理异常" class="headerlink" title="二.处理异常"></a>二.处理异常</h2><pre><code class="lang-python">import requests


# 爬取网页的通用代码框架
&quot;&quot;&quot;
网络连接有风险
处理异常很重要
&quot;&quot;&quot;
def getText(url):
    try:
        r = requests.get(url, timeout = 30)
        r.raise_for_status()  # 如果不是200， 引发HTMLError异常,跳到except
        r.encoding = r.apparent_encoding # 这步好像挺耗时的
        return r.text
    except:
        return &quot;Error occurred&quot;


if __name__ == &quot;__main__&quot;:
    url = &quot;https://fireworks99.github.io/&quot;
    print(getText(url))
</code></pre>
<h2 id="三-通用代码框架"><a href="#三-通用代码框架" class="headerlink" title="三.通用代码框架"></a>三.通用代码框架</h2><pre><code class="lang-python">import requests


# 爬取网页的通用代码框架
def getText(url):
    try:
        r = requests.get(url)
        r.raise_for_status()
        return &quot;Succeed&quot;
    except:
        return &quot;Error occurred&quot;


if __name__ == &quot;__main__&quot;:
    url = &quot;https://fireworks99.github.io/&quot;
    print(getText(url))
    r = requests.head(url) # 用较少的网络流量获取概要信息
    print(r.headers)
    print(r.text) # 空了
</code></pre>
<h2 id="四-模拟浏览器访问"><a href="#四-模拟浏览器访问" class="headerlink" title="四.模拟浏览器访问"></a>四.模拟浏览器访问</h2><pre><code class="lang-python">import requests

url = &quot;https://www.amazon.cn/dp/B072Z88B9T/ref=zg_bs_116169071_2?_encoding=UTF8&amp;psc=1&amp;refRID=7S6CK24KSH7ARE601YXF&quot;
r = requests.get(url)
print(r.status_code) # 503

&quot;&quot;&quot;
r.encoding = r.apparent_encoding
print(r.text)
# &quot;出现错误&quot; API造成
&quot;&quot;&quot;

&quot;&quot;&quot;
print(r.request.headers)
# {&#39;User-Agent&#39;: &#39;python-requests/2.19.1&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}
爬虫告诉亚马逊的服务器：此次访问是一个python的requests库的一个程序制造的(User-Agent)
那么亚马逊的服务器可以通过 来源审查 拒绝这样的访问
&quot;&quot;&quot;

&quot;&quot;&quot;
更改头部信息，模拟浏览器向网站发送请求
&quot;&quot;&quot;
kv = { &#39;user-agent&#39;: &#39;Mozilla/5.0&#39; } # 标准浏览器身份标识字段
r = requests.get(url, headers = kv)
print(r.status_code) # 200
print(r.request.headers)
# {&#39;user-agent&#39;: &#39;Mozilla/5.0&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}

print(r.text)
</code></pre>
<h2 id="五-提交关键词获取搜索结果"><a href="#五-提交关键词获取搜索结果" class="headerlink" title="五.提交关键词获取搜索结果"></a>五.提交关键词获取搜索结果</h2><pre><code class="lang-python">import requests

&quot;&quot;&quot;
向搜索引擎提交关键词并获取搜索结果

百度关键词接口：
http://www.baidu.com/s?wd=keyword

360关键词接口：
http://www.so.com/s?q=keyword
&quot;&quot;&quot;

keyword = &quot;Python&quot;
try:
    kv = { &#39;wd&#39;:keyword }
    r = requests.get(&quot;http://www.baidu.com/s&quot;, params=kv)
    print(r.request.url)
    r.raise_for_status()
    print(len(r.text))
except:
    print(&quot;Error occurred&quot;)


try:
    kv = { &#39;q&#39;:keyword }
    r = requests.get(&quot;http://www.so.com/s&quot;, params=kv)
    print(r.request.url)
    r.raise_for_status()
    print(len(r.text))
except:
    print(&quot;Error occurred&quot;)
</code></pre>
<h2 id="六-网络图片的爬取与存储"><a href="#六-网络图片的爬取与存储" class="headerlink" title="六.网络图片的爬取与存储"></a>六.网络图片的爬取与存储</h2><pre><code class="lang-python">import os
import requests

url = &quot;https://www.lifeofpix.com/wp-content/uploads/2019/08/DJI_0452-1600x1057.jpg&quot;
root = &quot;E://pycharm//crawl//pictures//&quot;
path = root + url.split(&#39;/&#39;)[-1] # url中以 &#39;/&#39; 分割的最后一部分

try:
    if not os.path.exists(root): # 根目录是否存在，不存在就建立
        os.mkdir(root)
    if not os.path.exists(path): # 文件是否存在，不存在才去爬取
        r = requests.get(url)
        with open(path, &#39;wb&#39;) as f:
            f.write(r.content)# 图片是以二进制形式保存的,恰好 r.content返回的也是二进制的内容
            f.close()
            print(&quot;Succeed&quot;)
    else:
        print(&quot;File already exists!&quot;)
except:
    print(&quot;Crawl failed!&quot;)
</code></pre>
<h2 id="七-网络图片批量爬取"><a href="#七-网络图片批量爬取" class="headerlink" title="七.网络图片批量爬取"></a>七.网络图片批量爬取</h2><pre><code class="lang-python">import os
import requests
from bs4 import BeautifulSoup

def getText(url):
    try:
        kv = {&#39;user-agent&#39;: &#39;Mozilla/5.0&#39;}
        r = requests.get(url, headers = kv) # 知乎有来源审查
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text
    except:
        return &quot;Error&quot;

if __name__ == &quot;__main__&quot;:
    url = &quot;https://www.zhihu.com/question/63202062/answer/209514500&quot;
    r = getText(url)
    bs_obj = BeautifulSoup(r, features=&#39;html.parser&#39;)
    pic_list = bs_obj.find_all(&quot;img&quot;)
    img_list = []
    idx = 0
    for link in pic_list:
        idx += 1
        if idx % 2 == 0:   # 偶数项是我们需要的
            img_list.append(link[&#39;src&#39;])
        else:
            pass

    root = &quot;E://pycharm//crawl//pictures//&quot;


    try:
        if not os.path.exists(root):  # 根目录是否存在，不存在就建立
            os.mkdir(root)

        for url in img_list:
            path = root + url.split(&#39;/&#39;)[-1]  # url中以 &#39;/&#39; 分割的最后一部分
            if not os.path.exists(path):  # 文件是否存在，不存在才去爬取
                r = requests.get(url)
                with open(path, &#39;wb&#39;) as f:
                    f.write(r.content)  # 图片是以二进制形式保存的,恰好 r.content返回的也是二进制的内容
                    f.close()
            else:
                pass
    except:
        print(&quot;Crawl failed!&quot;)
</code></pre>
<h2 id="八-IP地址归属地的自动查询"><a href="#八-IP地址归属地的自动查询" class="headerlink" title="八.IP地址归属地的自动查询"></a>八.IP地址归属地的自动查询</h2><pre><code class="lang-python">import requests

url = &quot;http://m.ip138.com/ip.asp?ip=&quot; # API
address = input()
try:
    kv = { &#39;user-agent&#39;: &#39;Mozilla/5.0&#39; }
    r = requests.get(url + address, headers=kv)
    r.raise_for_status()
    r.encoding = r.apparent_encoding
    print(r.text[-500:]) # 约束范围空间，否则可能影响IDE的使用
except:
    print(&quot;Error&quot;)
</code></pre>
<p><img src="https://i.postimg.cc/T10Sztpy/C3-NYO1-J-0-4-G0-SQT4-E.png" alt="API"></p>

		</div>

		<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC80NjIyNC8yMjczNQ==">
	<script type="text/javascript">
	   (function(d, s) {
	       var j, e = d.getElementsByTagName(s)[0];

	       if (typeof LivereTower === 'function') { return; }

	       j = d.createElement(s);
	       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
	       j.async = true;

	       e.parentNode.insertBefore(j, e);
	       
	       
	   })(document, 'script');
	</script>
<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->
		
	</article>

	<div id="toc">
		
	</div>

</div>

<!-- <div id="paginator"> -->
<!-- 	 -->
<!-- </div> -->




			</div>
		</div>

		<div id="bottom-outer">
			<div id="bottom-inner">
				Site by Baole Zhao | 
				Powered by <a href="http://hexo.io">Hexo</a> |
				theme <a href="https://github.com/fireworks99/hexo-theme-PreciousJoy">PreciousJoy</a>
			</div>
		</div>

		
	</div>





	
	<!-- scripts list from theme config.yml -->
	
	<script src="/js/jquery-3.5.1.min.js"></script>
	
	<script src="/js/PreciousJoy.js"></script>
	
	<script src="/js/highlight.pack.js"></script>
	
	<script src="/js/jquery.fancybox.min.js"></script>
	
	<script src="/js/search.js"></script>
	
	<script src="/js/load.js"></script>
	
	<script src="/js/jquery.mCustomScrollbar.concat.min.js"></script>
	
	<script src="/js/clipboard.min.js"></script>
	
	

	<script>hljs.initHighlightingOnLoad();</script>

</body>
</html>
